{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WB6nBMwdFU-U"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1230,
     "status": "ok",
     "timestamp": 1572089613169,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "l9C4aAIGOIUH",
    "outputId": "51a569eb-6524-435e-f350-ef3b1bfe7afb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ"
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1572089659112,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "UbiHj5YPOIUc",
    "outputId": "016f9299-83b2-44f7-ddf2-f17767fd298f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1572089664222,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "2ZJ2cfqXIRjx",
    "outputId": "664b0b09-5d68-4190-e3ff-173ff7615bc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj"
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "test_labels = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1235,
     "status": "ok",
     "timestamp": 1572089676878,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "RHV3b9mzOIUq",
    "outputId": "749847d0-fff0-43b5-8d9a-ae84e2096999",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "('First 5 examples now are: ', array([9, 0, 0, 3, 0], dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1055,
     "status": "ok",
     "timestamp": 1572089683841,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "8F_83stFHbfd",
    "outputId": "7cd74d2d-9f88-48b8-fb05-8e65cae695f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1746,
     "status": "ok",
     "timestamp": 1572089694348,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "dXAQBIrpHsri",
    "outputId": "9460a0c2-21f9-4ef3-ee1e-1b2768af94c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMK1jZP2AQRR"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 96
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1816,
     "status": "ok",
     "timestamp": 1572089710561,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "m78KhuA02o4T",
    "outputId": "2c5dcb1a-c131-478d-edb5-804b0e7a3c1d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAABPCAYAAADoZMHJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[trainY[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4"
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data\n",
    "#BatchNormalization -- used to feed normalizing to model\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "#Creates 10 equations\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "#If Sigmoid, give Binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_"
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1572089905574,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "O59C_-IgOIVB",
    "outputId": "720f08fc-5188-4f15-f42f-89b719a27186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3331 - accuracy: 0.2457 - val_loss: 17.2076 - val_accuracy: 0.1776\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.0994 - accuracy: 0.2946 - val_loss: 10.6929 - val_accuracy: 0.2214\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.9184 - accuracy: 0.3475 - val_loss: 7.8895 - val_accuracy: 0.2612\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.7767 - accuracy: 0.3969 - val_loss: 6.2910 - val_accuracy: 0.2956\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.6644 - accuracy: 0.4405 - val_loss: 5.2575 - val_accuracy: 0.3286\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.5742 - accuracy: 0.4773 - val_loss: 4.5413 - val_accuracy: 0.3557\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.5007 - accuracy: 0.5052 - val_loss: 4.0224 - val_accuracy: 0.3842\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.4399 - accuracy: 0.5278 - val_loss: 3.6331 - val_accuracy: 0.4078\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.3888 - accuracy: 0.5468 - val_loss: 3.3320 - val_accuracy: 0.4244\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3453 - accuracy: 0.5627 - val_loss: 3.0926 - val_accuracy: 0.4415\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3077 - accuracy: 0.5749 - val_loss: 2.8978 - val_accuracy: 0.4575\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.2748 - accuracy: 0.5868 - val_loss: 2.7358 - val_accuracy: 0.4731\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.2458 - accuracy: 0.5965 - val_loss: 2.5985 - val_accuracy: 0.4863\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.2199 - accuracy: 0.6058 - val_loss: 2.4800 - val_accuracy: 0.4982\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1965 - accuracy: 0.6126 - val_loss: 2.3762 - val_accuracy: 0.5075\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1753 - accuracy: 0.6185 - val_loss: 2.2842 - val_accuracy: 0.5169\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.1559 - accuracy: 0.6244 - val_loss: 2.2017 - val_accuracy: 0.5252\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.1381 - accuracy: 0.6300 - val_loss: 2.1270 - val_accuracy: 0.5323\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.1216 - accuracy: 0.6344 - val_loss: 2.0590 - val_accuracy: 0.5400\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.1063 - accuracy: 0.6391 - val_loss: 1.9966 - val_accuracy: 0.5450\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0921 - accuracy: 0.6434 - val_loss: 1.9390 - val_accuracy: 0.5503\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0787 - accuracy: 0.6463 - val_loss: 1.8857 - val_accuracy: 0.5556\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0662 - accuracy: 0.6500 - val_loss: 1.8361 - val_accuracy: 0.5616\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0544 - accuracy: 0.6535 - val_loss: 1.7898 - val_accuracy: 0.5672\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.0432 - accuracy: 0.6562 - val_loss: 1.7465 - val_accuracy: 0.5728\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0327 - accuracy: 0.6594 - val_loss: 1.7059 - val_accuracy: 0.5778\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0226 - accuracy: 0.6622 - val_loss: 1.6676 - val_accuracy: 0.5808\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0131 - accuracy: 0.6645 - val_loss: 1.6316 - val_accuracy: 0.5853\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0040 - accuracy: 0.6670 - val_loss: 1.5976 - val_accuracy: 0.5898\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.9953 - accuracy: 0.6694 - val_loss: 1.5654 - val_accuracy: 0.5933\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9870 - accuracy: 0.6720 - val_loss: 1.5349 - val_accuracy: 0.5978\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9790 - accuracy: 0.6741 - val_loss: 1.5059 - val_accuracy: 0.6014\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.9714 - accuracy: 0.6761 - val_loss: 1.4784 - val_accuracy: 0.6052\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9641 - accuracy: 0.6783 - val_loss: 1.4523 - val_accuracy: 0.6084\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.9570 - accuracy: 0.6803 - val_loss: 1.4273 - val_accuracy: 0.6115\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.9502 - accuracy: 0.6820 - val_loss: 1.4035 - val_accuracy: 0.6146\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9437 - accuracy: 0.6837 - val_loss: 1.3808 - val_accuracy: 0.6180\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9373 - accuracy: 0.6853 - val_loss: 1.3591 - val_accuracy: 0.6205\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9312 - accuracy: 0.6874 - val_loss: 1.3384 - val_accuracy: 0.6231\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9253 - accuracy: 0.6889 - val_loss: 1.3185 - val_accuracy: 0.6250\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.9196 - accuracy: 0.6903 - val_loss: 1.2994 - val_accuracy: 0.6271\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9141 - accuracy: 0.6921 - val_loss: 1.2812 - val_accuracy: 0.6299\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.9087 - accuracy: 0.6937 - val_loss: 1.2636 - val_accuracy: 0.6331\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.9035 - accuracy: 0.6954 - val_loss: 1.2468 - val_accuracy: 0.6359\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8985 - accuracy: 0.6968 - val_loss: 1.2306 - val_accuracy: 0.6382\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8936 - accuracy: 0.6984 - val_loss: 1.2150 - val_accuracy: 0.6406\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8888 - accuracy: 0.6998 - val_loss: 1.2000 - val_accuracy: 0.6424\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8842 - accuracy: 0.7012 - val_loss: 1.1855 - val_accuracy: 0.6443\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.8797 - accuracy: 0.7024 - val_loss: 1.1716 - val_accuracy: 0.6468\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.8753 - accuracy: 0.7035 - val_loss: 1.1581 - val_accuracy: 0.6486\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.8710 - accuracy: 0.7046 - val_loss: 1.1451 - val_accuracy: 0.6504\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8669 - accuracy: 0.7057 - val_loss: 1.1326 - val_accuracy: 0.6526\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8628 - accuracy: 0.7069 - val_loss: 1.1205 - val_accuracy: 0.6554\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8588 - accuracy: 0.7083 - val_loss: 1.1088 - val_accuracy: 0.6569\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8550 - accuracy: 0.7095 - val_loss: 1.0975 - val_accuracy: 0.6589\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8512 - accuracy: 0.7106 - val_loss: 1.0865 - val_accuracy: 0.6601\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8475 - accuracy: 0.7119 - val_loss: 1.0759 - val_accuracy: 0.6616\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.8439 - accuracy: 0.7129 - val_loss: 1.0657 - val_accuracy: 0.6627\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8404 - accuracy: 0.7139 - val_loss: 1.0557 - val_accuracy: 0.6641\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8370 - accuracy: 0.7150 - val_loss: 1.0461 - val_accuracy: 0.6658\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8336 - accuracy: 0.7159 - val_loss: 1.0368 - val_accuracy: 0.6669\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8304 - accuracy: 0.7167 - val_loss: 1.0277 - val_accuracy: 0.6690\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8271 - accuracy: 0.7177 - val_loss: 1.0189 - val_accuracy: 0.6701\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8240 - accuracy: 0.7187 - val_loss: 1.0104 - val_accuracy: 0.6717\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8209 - accuracy: 0.7198 - val_loss: 1.0021 - val_accuracy: 0.6728\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8179 - accuracy: 0.7208 - val_loss: 0.9941 - val_accuracy: 0.6743\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8149 - accuracy: 0.7218 - val_loss: 0.9863 - val_accuracy: 0.6759\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8120 - accuracy: 0.7229 - val_loss: 0.9787 - val_accuracy: 0.6775\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8092 - accuracy: 0.7236 - val_loss: 0.9713 - val_accuracy: 0.6785\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8064 - accuracy: 0.7246 - val_loss: 0.9642 - val_accuracy: 0.6803\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8037 - accuracy: 0.7255 - val_loss: 0.9572 - val_accuracy: 0.6818\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8010 - accuracy: 0.7267 - val_loss: 0.9504 - val_accuracy: 0.6834\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.7984 - accuracy: 0.7276 - val_loss: 0.9438 - val_accuracy: 0.6845\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.7958 - accuracy: 0.7285 - val_loss: 0.9374 - val_accuracy: 0.6860\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7932 - accuracy: 0.7292 - val_loss: 0.9311 - val_accuracy: 0.6877\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.7908 - accuracy: 0.7301 - val_loss: 0.9251 - val_accuracy: 0.6896\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.7883 - accuracy: 0.7309 - val_loss: 0.9191 - val_accuracy: 0.6918\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7859 - accuracy: 0.7317 - val_loss: 0.9134 - val_accuracy: 0.6934\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.7835 - accuracy: 0.7326 - val_loss: 0.9077 - val_accuracy: 0.6946\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7812 - accuracy: 0.7333 - val_loss: 0.9023 - val_accuracy: 0.6966\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.7789 - accuracy: 0.7340 - val_loss: 0.8969 - val_accuracy: 0.6970\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.7767 - accuracy: 0.7345 - val_loss: 0.8917 - val_accuracy: 0.6988\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.7745 - accuracy: 0.7352 - val_loss: 0.8866 - val_accuracy: 0.6999\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.7723 - accuracy: 0.7361 - val_loss: 0.8817 - val_accuracy: 0.7014\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7702 - accuracy: 0.7365 - val_loss: 0.8769 - val_accuracy: 0.7029\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.7681 - accuracy: 0.7372 - val_loss: 0.8721 - val_accuracy: 0.7039\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7660 - accuracy: 0.7379 - val_loss: 0.8676 - val_accuracy: 0.7046\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7640 - accuracy: 0.7388 - val_loss: 0.8631 - val_accuracy: 0.7064\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7620 - accuracy: 0.7395 - val_loss: 0.8587 - val_accuracy: 0.7071\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7600 - accuracy: 0.7401 - val_loss: 0.8544 - val_accuracy: 0.7084\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7581 - accuracy: 0.7406 - val_loss: 0.8502 - val_accuracy: 0.7099\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7561 - accuracy: 0.7414 - val_loss: 0.8462 - val_accuracy: 0.7111\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.7543 - accuracy: 0.7420 - val_loss: 0.8422 - val_accuracy: 0.7123\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.7524 - accuracy: 0.7426 - val_loss: 0.8383 - val_accuracy: 0.7130\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.7506 - accuracy: 0.7430 - val_loss: 0.8345 - val_accuracy: 0.7136\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7488 - accuracy: 0.7437 - val_loss: 0.8308 - val_accuracy: 0.7145\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7470 - accuracy: 0.7446 - val_loss: 0.8271 - val_accuracy: 0.7151\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7452 - accuracy: 0.7452 - val_loss: 0.8236 - val_accuracy: 0.7165\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7435 - accuracy: 0.7459 - val_loss: 0.8201 - val_accuracy: 0.7180\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7418 - accuracy: 0.7464 - val_loss: 0.8167 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b9c790750>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, train_labels, \n",
    "          validation_data=(testX, test_labels), \n",
    "          epochs=100,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF"
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2002,
     "status": "ok",
     "timestamp": 1572089915530,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "kndfpdidOIVI",
    "outputId": "c940f6c8-d56a-4450-c4c0-cb89df15fba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 10,986\n",
      "Trainable params: 9,418\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QZMmfiL7Y3v"
   },
   "outputs": [],
   "source": [
    "from keras.utils import normalize, to_categorical\n",
    "X_train = normalize(trainX, axis=1)\n",
    "X_test = normalize(testX, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tS6O2Nek0X1J"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data\n",
    "#BatchNormalization -- used to feed normalizing to model\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "#Creates 10 equations\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "#If Sigmoid, give Binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN"
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 151539,
     "status": "ok",
     "timestamp": 1572090085681,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "JNLR8tcBOIVP",
    "outputId": "9bfa280f-6f0b-4070-ce45-af634a8cd0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 2.6666 - accuracy: 0.1207 - val_loss: 2.2795 - val_accuracy: 0.2060\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.4655 - accuracy: 0.1569 - val_loss: 2.2545 - val_accuracy: 0.2153\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 2.2944 - accuracy: 0.1989 - val_loss: 2.2318 - val_accuracy: 0.2274\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 2.1484 - accuracy: 0.2429 - val_loss: 2.2110 - val_accuracy: 0.2429\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 2.0233 - accuracy: 0.2889 - val_loss: 2.1920 - val_accuracy: 0.2571\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.9153 - accuracy: 0.3305 - val_loss: 2.1746 - val_accuracy: 0.2699\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.8216 - accuracy: 0.3668 - val_loss: 2.1586 - val_accuracy: 0.2815\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 1.7397 - accuracy: 0.3988 - val_loss: 2.1438 - val_accuracy: 0.2913\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.6675 - accuracy: 0.4250 - val_loss: 2.1300 - val_accuracy: 0.3017\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 1.6034 - accuracy: 0.4465 - val_loss: 2.1171 - val_accuracy: 0.3119\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.5462 - accuracy: 0.4658 - val_loss: 2.1051 - val_accuracy: 0.3229\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 1.4948 - accuracy: 0.4835 - val_loss: 2.0937 - val_accuracy: 0.3330\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 1.4483 - accuracy: 0.4991 - val_loss: 2.0829 - val_accuracy: 0.3421\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.4061 - accuracy: 0.5137 - val_loss: 2.0727 - val_accuracy: 0.3506\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 1.3677 - accuracy: 0.5256 - val_loss: 2.0630 - val_accuracy: 0.3585\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.3324 - accuracy: 0.5379 - val_loss: 2.0537 - val_accuracy: 0.3659\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.3000 - accuracy: 0.5488 - val_loss: 2.0448 - val_accuracy: 0.3761\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.2702 - accuracy: 0.5589 - val_loss: 2.0362 - val_accuracy: 0.3850\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.2425 - accuracy: 0.5689 - val_loss: 2.0279 - val_accuracy: 0.3951\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.2169 - accuracy: 0.5789 - val_loss: 2.0199 - val_accuracy: 0.4046\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.1931 - accuracy: 0.5876 - val_loss: 2.0121 - val_accuracy: 0.4127\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 1.1709 - accuracy: 0.5956 - val_loss: 2.0046 - val_accuracy: 0.4223\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 1.1502 - accuracy: 0.6028 - val_loss: 1.9973 - val_accuracy: 0.4321\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.1308 - accuracy: 0.6095 - val_loss: 1.9902 - val_accuracy: 0.4409\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.1126 - accuracy: 0.6165 - val_loss: 1.9833 - val_accuracy: 0.4485\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.0955 - accuracy: 0.6227 - val_loss: 1.9765 - val_accuracy: 0.4563\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.0794 - accuracy: 0.6290 - val_loss: 1.9699 - val_accuracy: 0.4642\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 1.0642 - accuracy: 0.6346 - val_loss: 1.9634 - val_accuracy: 0.4723\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 1.0499 - accuracy: 0.6399 - val_loss: 1.9570 - val_accuracy: 0.4784\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 1.0363 - accuracy: 0.6446 - val_loss: 1.9508 - val_accuracy: 0.4851\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 1.0235 - accuracy: 0.6494 - val_loss: 1.9446 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 1.0113 - accuracy: 0.6533 - val_loss: 1.9386 - val_accuracy: 0.4989\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.9997 - accuracy: 0.6577 - val_loss: 1.9326 - val_accuracy: 0.5051\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.9887 - accuracy: 0.6614 - val_loss: 1.9268 - val_accuracy: 0.5119\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.9782 - accuracy: 0.6653 - val_loss: 1.9210 - val_accuracy: 0.5171\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.9682 - accuracy: 0.6695 - val_loss: 1.9153 - val_accuracy: 0.5229\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.9587 - accuracy: 0.6731 - val_loss: 1.9097 - val_accuracy: 0.5300\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9496 - accuracy: 0.6763 - val_loss: 1.9041 - val_accuracy: 0.5349\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.9408 - accuracy: 0.6791 - val_loss: 1.8986 - val_accuracy: 0.5396\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.9325 - accuracy: 0.6822 - val_loss: 1.8932 - val_accuracy: 0.5449\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.9244 - accuracy: 0.6854 - val_loss: 1.8878 - val_accuracy: 0.5497\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.9167 - accuracy: 0.6880 - val_loss: 1.8824 - val_accuracy: 0.5535\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.9093 - accuracy: 0.6907 - val_loss: 1.8771 - val_accuracy: 0.5577\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.9022 - accuracy: 0.6930 - val_loss: 1.8719 - val_accuracy: 0.5626\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.8954 - accuracy: 0.6952 - val_loss: 1.8667 - val_accuracy: 0.5672\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.8888 - accuracy: 0.6975 - val_loss: 1.8615 - val_accuracy: 0.5701\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8824 - accuracy: 0.6998 - val_loss: 1.8564 - val_accuracy: 0.5741\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.8763 - accuracy: 0.7015 - val_loss: 1.8513 - val_accuracy: 0.5781\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.8704 - accuracy: 0.7037 - val_loss: 1.8462 - val_accuracy: 0.5821\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.8647 - accuracy: 0.7056 - val_loss: 1.8412 - val_accuracy: 0.5859\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8592 - accuracy: 0.7074 - val_loss: 1.8362 - val_accuracy: 0.5895\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8538 - accuracy: 0.7094 - val_loss: 1.8312 - val_accuracy: 0.5923\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.8486 - accuracy: 0.7109 - val_loss: 1.8263 - val_accuracy: 0.5951\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.8436 - accuracy: 0.7126 - val_loss: 1.8213 - val_accuracy: 0.5988\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.8388 - accuracy: 0.7144 - val_loss: 1.8164 - val_accuracy: 0.6024\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.8341 - accuracy: 0.7158 - val_loss: 1.8116 - val_accuracy: 0.6048\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8295 - accuracy: 0.7172 - val_loss: 1.8067 - val_accuracy: 0.6065\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.8251 - accuracy: 0.7187 - val_loss: 1.8019 - val_accuracy: 0.6092\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8208 - accuracy: 0.7201 - val_loss: 1.7970 - val_accuracy: 0.6116\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.8166 - accuracy: 0.7218 - val_loss: 1.7922 - val_accuracy: 0.6144\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8125 - accuracy: 0.7230 - val_loss: 1.7874 - val_accuracy: 0.6166\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.8086 - accuracy: 0.7241 - val_loss: 1.7827 - val_accuracy: 0.6204\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.8047 - accuracy: 0.7254 - val_loss: 1.7779 - val_accuracy: 0.6220\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.8010 - accuracy: 0.7268 - val_loss: 1.7732 - val_accuracy: 0.6238\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.7973 - accuracy: 0.7279 - val_loss: 1.7684 - val_accuracy: 0.6257\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7938 - accuracy: 0.7289 - val_loss: 1.7637 - val_accuracy: 0.6282\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7903 - accuracy: 0.7304 - val_loss: 1.7590 - val_accuracy: 0.6292\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7870 - accuracy: 0.7315 - val_loss: 1.7543 - val_accuracy: 0.6314\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.7837 - accuracy: 0.7326 - val_loss: 1.7496 - val_accuracy: 0.6336\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7804 - accuracy: 0.7333 - val_loss: 1.7450 - val_accuracy: 0.6356\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.7773 - accuracy: 0.7341 - val_loss: 1.7403 - val_accuracy: 0.6375\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.7742 - accuracy: 0.7354 - val_loss: 1.7356 - val_accuracy: 0.6398\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7713 - accuracy: 0.7364 - val_loss: 1.7310 - val_accuracy: 0.6418\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7683 - accuracy: 0.7374 - val_loss: 1.7263 - val_accuracy: 0.6439\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7655 - accuracy: 0.7385 - val_loss: 1.7217 - val_accuracy: 0.6458\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7627 - accuracy: 0.7393 - val_loss: 1.7171 - val_accuracy: 0.6480\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.7599 - accuracy: 0.7400 - val_loss: 1.7125 - val_accuracy: 0.6484\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7573 - accuracy: 0.7407 - val_loss: 1.7079 - val_accuracy: 0.6502\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7547 - accuracy: 0.7417 - val_loss: 1.7032 - val_accuracy: 0.6513\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7521 - accuracy: 0.7426 - val_loss: 1.6986 - val_accuracy: 0.6528\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7496 - accuracy: 0.7434 - val_loss: 1.6941 - val_accuracy: 0.6535\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7471 - accuracy: 0.7441 - val_loss: 1.6895 - val_accuracy: 0.6549\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7447 - accuracy: 0.7448 - val_loss: 1.6849 - val_accuracy: 0.6571\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.7423 - accuracy: 0.7458 - val_loss: 1.6803 - val_accuracy: 0.6584\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7400 - accuracy: 0.7465 - val_loss: 1.6757 - val_accuracy: 0.6601\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.7378 - accuracy: 0.7471 - val_loss: 1.6711 - val_accuracy: 0.6615\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7355 - accuracy: 0.7478 - val_loss: 1.6666 - val_accuracy: 0.6624\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.7334 - accuracy: 0.7486 - val_loss: 1.6620 - val_accuracy: 0.6631\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.7312 - accuracy: 0.7494 - val_loss: 1.6574 - val_accuracy: 0.6640\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7291 - accuracy: 0.7499 - val_loss: 1.6529 - val_accuracy: 0.6651\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.7270 - accuracy: 0.7507 - val_loss: 1.6483 - val_accuracy: 0.6674\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.7250 - accuracy: 0.7513 - val_loss: 1.6438 - val_accuracy: 0.6680\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7230 - accuracy: 0.7521 - val_loss: 1.6392 - val_accuracy: 0.6689\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.7211 - accuracy: 0.7526 - val_loss: 1.6347 - val_accuracy: 0.6698\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7191 - accuracy: 0.7531 - val_loss: 1.6301 - val_accuracy: 0.6718\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7172 - accuracy: 0.7537 - val_loss: 1.6256 - val_accuracy: 0.6727\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7154 - accuracy: 0.7545 - val_loss: 1.6211 - val_accuracy: 0.6748\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.7136 - accuracy: 0.7550 - val_loss: 1.6165 - val_accuracy: 0.6755\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7118 - accuracy: 0.7555 - val_loss: 1.6120 - val_accuracy: 0.6766\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7100 - accuracy: 0.7562 - val_loss: 1.6075 - val_accuracy: 0.6780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b9b120e50>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, train_labels, \n",
    "          validation_data=(X_test, test_labels), \n",
    "          epochs=100,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.001)\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 149659,
     "status": "ok",
     "timestamp": 1572090326965,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "pJUqA5T4OIVc",
    "outputId": "2e15d9bb-4a71-4f81-f385-d2813e51d6e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.7083 - accuracy: 0.7566 - val_loss: 1.6029 - val_accuracy: 0.6787\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7066 - accuracy: 0.7569 - val_loss: 1.5984 - val_accuracy: 0.6800\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.7049 - accuracy: 0.7574 - val_loss: 1.5939 - val_accuracy: 0.6812\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7032 - accuracy: 0.7579 - val_loss: 1.5894 - val_accuracy: 0.6826\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7016 - accuracy: 0.7586 - val_loss: 1.5848 - val_accuracy: 0.6839\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.7000 - accuracy: 0.7591 - val_loss: 1.5803 - val_accuracy: 0.6850\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.6984 - accuracy: 0.7596 - val_loss: 1.5758 - val_accuracy: 0.6862\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6968 - accuracy: 0.7600 - val_loss: 1.5713 - val_accuracy: 0.6879\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6953 - accuracy: 0.7606 - val_loss: 1.5668 - val_accuracy: 0.6886\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6938 - accuracy: 0.7611 - val_loss: 1.5622 - val_accuracy: 0.6901\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6923 - accuracy: 0.7616 - val_loss: 1.5577 - val_accuracy: 0.6905\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6908 - accuracy: 0.7620 - val_loss: 1.5532 - val_accuracy: 0.6916\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.6894 - accuracy: 0.7625 - val_loss: 1.5487 - val_accuracy: 0.6921\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6880 - accuracy: 0.7629 - val_loss: 1.5442 - val_accuracy: 0.6928\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6866 - accuracy: 0.7632 - val_loss: 1.5397 - val_accuracy: 0.6941\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6852 - accuracy: 0.7636 - val_loss: 1.5352 - val_accuracy: 0.6952\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6838 - accuracy: 0.7639 - val_loss: 1.5307 - val_accuracy: 0.6966\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6824 - accuracy: 0.7642 - val_loss: 1.5262 - val_accuracy: 0.6981\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6811 - accuracy: 0.7647 - val_loss: 1.5217 - val_accuracy: 0.6993\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6798 - accuracy: 0.7652 - val_loss: 1.5172 - val_accuracy: 0.7003\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6785 - accuracy: 0.7657 - val_loss: 1.5127 - val_accuracy: 0.7007\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6772 - accuracy: 0.7662 - val_loss: 1.5082 - val_accuracy: 0.7024\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6760 - accuracy: 0.7664 - val_loss: 1.5037 - val_accuracy: 0.7028\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6747 - accuracy: 0.7666 - val_loss: 1.4992 - val_accuracy: 0.7034\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6735 - accuracy: 0.7670 - val_loss: 1.4947 - val_accuracy: 0.7044\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6723 - accuracy: 0.7674 - val_loss: 1.4902 - val_accuracy: 0.7053\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6711 - accuracy: 0.7679 - val_loss: 1.4857 - val_accuracy: 0.7063\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6699 - accuracy: 0.7684 - val_loss: 1.4812 - val_accuracy: 0.7073\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6687 - accuracy: 0.7688 - val_loss: 1.4768 - val_accuracy: 0.7082\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6676 - accuracy: 0.7691 - val_loss: 1.4723 - val_accuracy: 0.7091\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6664 - accuracy: 0.7694 - val_loss: 1.4678 - val_accuracy: 0.7098\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6653 - accuracy: 0.7698 - val_loss: 1.4633 - val_accuracy: 0.7107\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6642 - accuracy: 0.7702 - val_loss: 1.4588 - val_accuracy: 0.7116\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6631 - accuracy: 0.7704 - val_loss: 1.4544 - val_accuracy: 0.7127\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6620 - accuracy: 0.7707 - val_loss: 1.4499 - val_accuracy: 0.7133\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6609 - accuracy: 0.7711 - val_loss: 1.4454 - val_accuracy: 0.7144\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6598 - accuracy: 0.7714 - val_loss: 1.4410 - val_accuracy: 0.7148\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6588 - accuracy: 0.7717 - val_loss: 1.4365 - val_accuracy: 0.7159\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6578 - accuracy: 0.7721 - val_loss: 1.4320 - val_accuracy: 0.7167\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6567 - accuracy: 0.7725 - val_loss: 1.4276 - val_accuracy: 0.7179\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6557 - accuracy: 0.7728 - val_loss: 1.4231 - val_accuracy: 0.7188\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.6547 - accuracy: 0.7731 - val_loss: 1.4187 - val_accuracy: 0.7200\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.6537 - accuracy: 0.7734 - val_loss: 1.4142 - val_accuracy: 0.7214\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.6527 - accuracy: 0.7737 - val_loss: 1.4098 - val_accuracy: 0.7219\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.6518 - accuracy: 0.7740 - val_loss: 1.4053 - val_accuracy: 0.7224\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.6508 - accuracy: 0.7743 - val_loss: 1.4009 - val_accuracy: 0.7234\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6498 - accuracy: 0.7746 - val_loss: 1.3964 - val_accuracy: 0.7240\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6489 - accuracy: 0.7750 - val_loss: 1.3920 - val_accuracy: 0.7244\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6480 - accuracy: 0.7751 - val_loss: 1.3876 - val_accuracy: 0.7259\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6470 - accuracy: 0.7755 - val_loss: 1.3831 - val_accuracy: 0.7267\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6461 - accuracy: 0.7757 - val_loss: 1.3787 - val_accuracy: 0.7272\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.6452 - accuracy: 0.7761 - val_loss: 1.3743 - val_accuracy: 0.7277\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6443 - accuracy: 0.7764 - val_loss: 1.3699 - val_accuracy: 0.7284\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6434 - accuracy: 0.7768 - val_loss: 1.3655 - val_accuracy: 0.7291\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6426 - accuracy: 0.7772 - val_loss: 1.3611 - val_accuracy: 0.7292\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6417 - accuracy: 0.7777 - val_loss: 1.3567 - val_accuracy: 0.7298\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.6408 - accuracy: 0.7779 - val_loss: 1.3523 - val_accuracy: 0.7297\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6400 - accuracy: 0.7781 - val_loss: 1.3479 - val_accuracy: 0.7310\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.6391 - accuracy: 0.7784 - val_loss: 1.3435 - val_accuracy: 0.7319\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6383 - accuracy: 0.7788 - val_loss: 1.3391 - val_accuracy: 0.7321\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6375 - accuracy: 0.7790 - val_loss: 1.3347 - val_accuracy: 0.7329\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6367 - accuracy: 0.7793 - val_loss: 1.3303 - val_accuracy: 0.7338\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6358 - accuracy: 0.7796 - val_loss: 1.3259 - val_accuracy: 0.7344\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6350 - accuracy: 0.7799 - val_loss: 1.3216 - val_accuracy: 0.7354\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6342 - accuracy: 0.7802 - val_loss: 1.3172 - val_accuracy: 0.7359\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6334 - accuracy: 0.7804 - val_loss: 1.3128 - val_accuracy: 0.7369\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6327 - accuracy: 0.7806 - val_loss: 1.3085 - val_accuracy: 0.7376\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6319 - accuracy: 0.7809 - val_loss: 1.3041 - val_accuracy: 0.7384\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6311 - accuracy: 0.7813 - val_loss: 1.2998 - val_accuracy: 0.7390\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6304 - accuracy: 0.7815 - val_loss: 1.2955 - val_accuracy: 0.7397\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6296 - accuracy: 0.7818 - val_loss: 1.2911 - val_accuracy: 0.7402\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6289 - accuracy: 0.7821 - val_loss: 1.2868 - val_accuracy: 0.7411\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6281 - accuracy: 0.7822 - val_loss: 1.2825 - val_accuracy: 0.7416\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6274 - accuracy: 0.7826 - val_loss: 1.2782 - val_accuracy: 0.7419\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6267 - accuracy: 0.7828 - val_loss: 1.2739 - val_accuracy: 0.7423\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6259 - accuracy: 0.7830 - val_loss: 1.2696 - val_accuracy: 0.7427\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6252 - accuracy: 0.7832 - val_loss: 1.2653 - val_accuracy: 0.7432\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.6245 - accuracy: 0.7835 - val_loss: 1.2610 - val_accuracy: 0.7437\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6238 - accuracy: 0.7837 - val_loss: 1.2567 - val_accuracy: 0.7445\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6231 - accuracy: 0.7839 - val_loss: 1.2525 - val_accuracy: 0.7449\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.6224 - accuracy: 0.7842 - val_loss: 1.2482 - val_accuracy: 0.7457\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6217 - accuracy: 0.7843 - val_loss: 1.2439 - val_accuracy: 0.7469\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6210 - accuracy: 0.7845 - val_loss: 1.2397 - val_accuracy: 0.7474\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6204 - accuracy: 0.7847 - val_loss: 1.2354 - val_accuracy: 0.7483\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6197 - accuracy: 0.7847 - val_loss: 1.2312 - val_accuracy: 0.7489\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6190 - accuracy: 0.7850 - val_loss: 1.2270 - val_accuracy: 0.7497\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6184 - accuracy: 0.7851 - val_loss: 1.2228 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6177 - accuracy: 0.7854 - val_loss: 1.2186 - val_accuracy: 0.7509\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6171 - accuracy: 0.7855 - val_loss: 1.2143 - val_accuracy: 0.7513\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.6164 - accuracy: 0.7857 - val_loss: 1.2102 - val_accuracy: 0.7519\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6158 - accuracy: 0.7859 - val_loss: 1.2060 - val_accuracy: 0.7525\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.6152 - accuracy: 0.7861 - val_loss: 1.2018 - val_accuracy: 0.7528\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.6145 - accuracy: 0.7865 - val_loss: 1.1976 - val_accuracy: 0.7525\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6139 - accuracy: 0.7868 - val_loss: 1.1935 - val_accuracy: 0.7526\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.6133 - accuracy: 0.7870 - val_loss: 1.1893 - val_accuracy: 0.7533\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6127 - accuracy: 0.7872 - val_loss: 1.1852 - val_accuracy: 0.7537\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6121 - accuracy: 0.7875 - val_loss: 1.1810 - val_accuracy: 0.7545\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6115 - accuracy: 0.7877 - val_loss: 1.1769 - val_accuracy: 0.7553\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6109 - accuracy: 0.7878 - val_loss: 1.1728 - val_accuracy: 0.7556\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.6103 - accuracy: 0.7880 - val_loss: 1.1687 - val_accuracy: 0.7560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b9c7be990>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, train_labels, \n",
    "          validation_data=(X_test, test_labels), \n",
    "          epochs=100,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk"
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "#Add 1st hidden layer\n",
    "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7oIymROIVp"
   },
   "outputs": [],
   "source": [
    "#Add 2nd hidden layer\n",
    "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-O-fFxnOIVt"
   },
   "outputs": [],
   "source": [
    "#Add OUTPUT layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tWmTD8EkgCdH"
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiP7IL52OIVw"
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0"
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1209,
     "status": "ok",
     "timestamp": 1572090353224,
     "user": {
      "displayName": "Ritul Singh",
      "photoUrl": "",
      "userId": "05150505717387322309"
     },
     "user_tz": -330
    },
    "id": "h4ojW6-oOIV2",
    "outputId": "43ffadda-16a8-4a7f-e31d-1bc50be618fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_2 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 23,196\n",
      "Trainable params: 21,628\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5"
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bIkbMEN5OIV7",
    "outputId": "6a087f47-cf07-4c18-a74c-bf50b74e41a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.6639 - accuracy: 0.1000 - val_loss: 2.6412 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.6412 - accuracy: 0.1000 - val_loss: 2.6199 - val_accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.6199 - accuracy: 0.1000 - val_loss: 2.5999 - val_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.5999 - accuracy: 0.1000 - val_loss: 2.5811 - val_accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.5811 - accuracy: 0.1000 - val_loss: 2.5635 - val_accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 2.5635 - accuracy: 0.1000 - val_loss: 2.5470 - val_accuracy: 0.1000\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 2.5470 - accuracy: 0.1000 - val_loss: 2.5316 - val_accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 2.5316 - accuracy: 0.1000 - val_loss: 2.5171 - val_accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 2.5171 - accuracy: 0.1000 - val_loss: 2.5035 - val_accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.5035 - accuracy: 0.1000 - val_loss: 2.4908 - val_accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 2.4908 - accuracy: 0.1000 - val_loss: 2.4789 - val_accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.4789 - accuracy: 0.1000 - val_loss: 2.4678 - val_accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.4677 - accuracy: 0.1000 - val_loss: 2.4573 - val_accuracy: 0.1000\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.4573 - accuracy: 0.1000 - val_loss: 2.4476 - val_accuracy: 0.1000\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.4476 - accuracy: 0.1000 - val_loss: 2.4385 - val_accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 2.4384 - accuracy: 0.1000 - val_loss: 2.4299 - val_accuracy: 0.1000\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 2.4299 - accuracy: 0.1000 - val_loss: 2.4219 - val_accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.4219 - accuracy: 0.1000 - val_loss: 2.4145 - val_accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.4144 - accuracy: 0.1000 - val_loss: 2.4075 - val_accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.4074 - accuracy: 0.1000 - val_loss: 2.4009 - val_accuracy: 0.1000\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.4009 - accuracy: 0.1000 - val_loss: 2.3948 - val_accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3948 - accuracy: 0.1000 - val_loss: 2.3891 - val_accuracy: 0.1000\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3890 - accuracy: 0.1000 - val_loss: 2.3837 - val_accuracy: 0.1000\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3837 - accuracy: 0.1000 - val_loss: 2.3787 - val_accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3786 - accuracy: 0.1000 - val_loss: 2.3740 - val_accuracy: 0.1000\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3739 - accuracy: 0.1000 - val_loss: 2.3696 - val_accuracy: 0.1000\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3695 - accuracy: 0.1000 - val_loss: 2.3655 - val_accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3654 - accuracy: 0.1001 - val_loss: 2.3616 - val_accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 2.3615 - accuracy: 0.1001 - val_loss: 2.3580 - val_accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3579 - accuracy: 0.1002 - val_loss: 2.3546 - val_accuracy: 0.1000\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3545 - accuracy: 0.1002 - val_loss: 2.3514 - val_accuracy: 0.1000\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.3514 - accuracy: 0.1003 - val_loss: 2.3484 - val_accuracy: 0.1000\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3484 - accuracy: 0.1004 - val_loss: 2.3457 - val_accuracy: 0.1000\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.3456 - accuracy: 0.1004 - val_loss: 2.3430 - val_accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3430 - accuracy: 0.1005 - val_loss: 2.3406 - val_accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 2.3405 - accuracy: 0.1005 - val_loss: 2.3383 - val_accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3382 - accuracy: 0.0998 - val_loss: 2.3361 - val_accuracy: 0.1000\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3360 - accuracy: 0.0992 - val_loss: 2.3341 - val_accuracy: 0.0999\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3340 - accuracy: 0.0988 - val_loss: 2.3322 - val_accuracy: 0.0998\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3321 - accuracy: 0.0985 - val_loss: 2.3304 - val_accuracy: 0.0997\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3303 - accuracy: 0.0980 - val_loss: 2.3288 - val_accuracy: 0.0995\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3286 - accuracy: 0.0977 - val_loss: 2.3272 - val_accuracy: 0.0986\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 2.3271 - accuracy: 0.0972 - val_loss: 2.3257 - val_accuracy: 0.0978\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3256 - accuracy: 0.0967 - val_loss: 2.3243 - val_accuracy: 0.0964\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 2.3242 - accuracy: 0.0965 - val_loss: 2.3230 - val_accuracy: 0.0952\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3229 - accuracy: 0.0963 - val_loss: 2.3218 - val_accuracy: 0.0937\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3217 - accuracy: 0.0960 - val_loss: 2.3207 - val_accuracy: 0.0916\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3205 - accuracy: 0.0955 - val_loss: 2.3196 - val_accuracy: 0.0900\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3194 - accuracy: 0.0952 - val_loss: 2.3186 - val_accuracy: 0.0887\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3184 - accuracy: 0.0949 - val_loss: 2.3176 - val_accuracy: 0.0873\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.3175 - accuracy: 0.0947 - val_loss: 2.3167 - val_accuracy: 0.0850\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3166 - accuracy: 0.0945 - val_loss: 2.3159 - val_accuracy: 0.0827\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 2.3157 - accuracy: 0.0943 - val_loss: 2.3151 - val_accuracy: 0.0801\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3149 - accuracy: 0.0939 - val_loss: 2.3143 - val_accuracy: 0.0786\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3142 - accuracy: 0.0938 - val_loss: 2.3136 - val_accuracy: 0.0763\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.3135 - accuracy: 0.0935 - val_loss: 2.3130 - val_accuracy: 0.0743\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.3128 - accuracy: 0.0933 - val_loss: 2.3124 - val_accuracy: 0.0730\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3122 - accuracy: 0.0932 - val_loss: 2.3118 - val_accuracy: 0.0724\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3116 - accuracy: 0.0931 - val_loss: 2.3112 - val_accuracy: 0.0716\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3111 - accuracy: 0.0930 - val_loss: 2.3107 - val_accuracy: 0.0701\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 2.3105 - accuracy: 0.0930 - val_loss: 2.3102 - val_accuracy: 0.0685\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3100 - accuracy: 0.0929 - val_loss: 2.3098 - val_accuracy: 0.0675\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.3096 - accuracy: 0.0930 - val_loss: 2.3093 - val_accuracy: 0.0671\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3091 - accuracy: 0.0929 - val_loss: 2.3089 - val_accuracy: 0.0670\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3087 - accuracy: 0.0928 - val_loss: 2.3085 - val_accuracy: 0.0666\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3084 - accuracy: 0.0929 - val_loss: 2.3082 - val_accuracy: 0.0667\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3080 - accuracy: 0.0929 - val_loss: 2.3078 - val_accuracy: 0.0663\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3076 - accuracy: 0.0930 - val_loss: 2.3075 - val_accuracy: 0.0657\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3073 - accuracy: 0.0930 - val_loss: 2.3072 - val_accuracy: 0.0657\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.3070 - accuracy: 0.0931 - val_loss: 2.3069 - val_accuracy: 0.0657\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3067 - accuracy: 0.0931 - val_loss: 2.3067 - val_accuracy: 0.0657\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3065 - accuracy: 0.0933 - val_loss: 2.3064 - val_accuracy: 0.0659\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3062 - accuracy: 0.0934 - val_loss: 2.3062 - val_accuracy: 0.0662\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3060 - accuracy: 0.0935 - val_loss: 2.3060 - val_accuracy: 0.0661\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3057 - accuracy: 0.0936 - val_loss: 2.3057 - val_accuracy: 0.0663\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3055 - accuracy: 0.0938 - val_loss: 2.3055 - val_accuracy: 0.0664\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3053 - accuracy: 0.0939 - val_loss: 2.3053 - val_accuracy: 0.0669\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3051 - accuracy: 0.0941 - val_loss: 2.3052 - val_accuracy: 0.0673\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3049 - accuracy: 0.0941 - val_loss: 2.3050 - val_accuracy: 0.0677\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.3048 - accuracy: 0.0942 - val_loss: 2.3048 - val_accuracy: 0.0679\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3046 - accuracy: 0.0942 - val_loss: 2.3047 - val_accuracy: 0.0687\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3045 - accuracy: 0.0943 - val_loss: 2.3045 - val_accuracy: 0.0689\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3043 - accuracy: 0.0944 - val_loss: 2.3044 - val_accuracy: 0.0691\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3042 - accuracy: 0.0945 - val_loss: 2.3043 - val_accuracy: 0.0693\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3040 - accuracy: 0.0945 - val_loss: 2.3042 - val_accuracy: 0.0696\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3039 - accuracy: 0.0946 - val_loss: 2.3041 - val_accuracy: 0.0705\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3038 - accuracy: 0.0947 - val_loss: 2.3039 - val_accuracy: 0.0715\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3037 - accuracy: 0.0947 - val_loss: 2.3038 - val_accuracy: 0.0721\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3036 - accuracy: 0.0948 - val_loss: 2.3037 - val_accuracy: 0.0724\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3035 - accuracy: 0.0948 - val_loss: 2.3037 - val_accuracy: 0.0731\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 2.3034 - accuracy: 0.0949 - val_loss: 2.3036 - val_accuracy: 0.0737\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3033 - accuracy: 0.0951 - val_loss: 2.3035 - val_accuracy: 0.0740\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3032 - accuracy: 0.0951 - val_loss: 2.3034 - val_accuracy: 0.0745\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3031 - accuracy: 0.0952 - val_loss: 2.3033 - val_accuracy: 0.0745\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3031 - accuracy: 0.0953 - val_loss: 2.3033 - val_accuracy: 0.0747\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3030 - accuracy: 0.0953 - val_loss: 2.3032 - val_accuracy: 0.0751\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3029 - accuracy: 0.0953 - val_loss: 2.3031 - val_accuracy: 0.0754\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 2.3029 - accuracy: 0.0953 - val_loss: 2.3031 - val_accuracy: 0.0766\n",
      "Epoch 99/100\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, train_labels, \n",
    "          validation_data=(X_test, test_labels), \n",
    "          epochs=100,\n",
    "          batch_size=trainX.shape[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_ExternalLab_AIML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
