{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The objective of the project is to learn how to implement a simple image classification pipeline based on the k-Nearest\n",
    "Neighbour and a deep neural network. The goals of this assignment are as follows:  \n",
    "● Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages) \n",
    "● Data fetching and understand the train/val/test splits. \n",
    "● Implement and apply an optimal k-Nearest Neighbor (kNN) classifier (7.5 points) \n",
    "● Print the classification metric report (2.5 points) \n",
    "● Implement and apply a deep neural network classifier including (feedforward  neural network, RELU activations) (5 points) \n",
    "● Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost\n",
    " functions) (2.5 points) \n",
    "● Implement batch normalization for training the neural network (2.5 points)  \n",
    "● Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics (5 points)  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File('SVHN_single_grey1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = np.array(h5py.File('SVHN_single_grey1.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test\n",
      "X_train\n",
      "X_val\n",
      "y_test\n",
      "y_train\n",
      "y_val\n"
     ]
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(key) #Names of the groups in HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = f['X_train'][:]\n",
    "X_test = f['X_test'][:]\n",
    "X_val = f['X_val'][:]\n",
    "y_test = f['y_test'][:]\n",
    "y_train = f['y_train'][:]\n",
    "y_val = f['y_val'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<f4')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('<f4')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('<f4')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtype\n",
    "X_train.dtype\n",
    "X_val.dtype\n",
    "y_test.dtype\n",
    "y_train.dtype\n",
    "y_val.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_test.shape\n",
    "X_val.shape\n",
    "y_train.shape\n",
    "y_test.shape\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ml = X_train.reshape(X_train.shape[0], 32*32).astype('float32')\n",
    "X_test_ml = X_test.reshape(X_test.shape[0], 32*32).astype('float32')\n",
    "X_val_ml = X_val.reshape(X_val.shape[0], 32*32).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ml.shape\n",
    "X_test_ml.shape\n",
    "X_val_ml.shape\n",
    "y_train.shape\n",
    "y_test.shape\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = np.unique(y_train).shape[0]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar to one hot encoding, here it converts one number to ten numbers\n",
    "import keras\n",
    "trainY = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "testY = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "valY = keras.utils.to_categorical(y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement and apply an optimal k-Nearest Neighbor (kNN) classifier (7.5 points) \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH = KNeighborsClassifier(n_neighbors= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNH.fit(X_train_ml, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5349666666666667\n"
     ]
    }
   ],
   "source": [
    "#Print the classification metric report (2.5 points) \n",
    "predictions = NNH.predict(X_val_ml)\n",
    "score = NNH.score(X_val_ml, valY)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3783888888888889\n"
     ]
    }
   ],
   "source": [
    "#Print the classification metric report (2.5 points) \n",
    "predictions = NNH.predict(X_test_ml)\n",
    "score = NNH.score(X_test_ml, testY)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Implement and apply a deep neural network classifier including (feedforward  neural network, RELU activations) (5 points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ranupran\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ranupran\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ranupran\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ranupran\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize model, reshape & normalize data\n",
    "import keras\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Reshape((1024,),input_shape=(32,32,)))\n",
    "model.add(keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ranupran\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add 1st hidden layer\n",
    "model.add(keras.layers.Dense(200, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add 2nd hidden layer\n",
    "model.add(keras.layers.Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add 3rd hidden layer\n",
    "model.add(keras.layers.Dense(60, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add 4th hidden layer\n",
    "model.add(keras.layers.Dense(30, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add OUTPUT layer\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost\n",
    "functions) (2.5 points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ranupran\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 237,396\n",
      "Trainable params: 235,348\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Implement batch normalization for training the neural network (2.5 points)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(42000, 10)\n",
      "(60000, 1024)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_ml.shape)\n",
    "print(trainY.shape)\n",
    "print(X_val_ml.shape)\n",
    "print(valY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ranupran\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 8s 196us/step - loss: 2.2228 - acc: 0.1859 - val_loss: 2.0645 - val_acc: 0.3095\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 8s 188us/step - loss: 1.7982 - acc: 0.4077 - val_loss: 1.5015 - val_acc: 0.5188\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 8s 186us/step - loss: 1.3605 - acc: 0.5695 - val_loss: 1.1828 - val_acc: 0.6419\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 8s 183us/step - loss: 1.1444 - acc: 0.6497 - val_loss: 1.0283 - val_acc: 0.6900\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 8s 202us/step - loss: 1.0117 - acc: 0.6901 - val_loss: 0.9175 - val_acc: 0.7259\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 8s 186us/step - loss: 0.9185 - acc: 0.7225 - val_loss: 0.8568 - val_acc: 0.7410\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 8s 192us/step - loss: 0.8567 - acc: 0.7404 - val_loss: 0.8017 - val_acc: 0.7588\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 7s 173us/step - loss: 0.8031 - acc: 0.7539 - val_loss: 0.7429 - val_acc: 0.7789\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 7s 169us/step - loss: 0.7611 - acc: 0.7695 - val_loss: 0.7045 - val_acc: 0.7934\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 7s 164us/step - loss: 0.7232 - acc: 0.7797 - val_loss: 0.6637 - val_acc: 0.8056\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 7s 166us/step - loss: 0.6854 - acc: 0.7921 - val_loss: 0.6448 - val_acc: 0.8091\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 7s 165us/step - loss: 0.6544 - acc: 0.8015 - val_loss: 0.6362 - val_acc: 0.8128\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 8s 179us/step - loss: 0.6288 - acc: 0.8080 - val_loss: 0.6186 - val_acc: 0.8133\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 7s 171us/step - loss: 0.6074 - acc: 0.8150 - val_loss: 0.5660 - val_acc: 0.8349\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 8s 181us/step - loss: 0.5873 - acc: 0.8196 - val_loss: 0.5563 - val_acc: 0.8362\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 9s 212us/step - loss: 0.5690 - acc: 0.8275 - val_loss: 0.5492 - val_acc: 0.8363\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 7s 176us/step - loss: 0.5521 - acc: 0.8296 - val_loss: 0.5435 - val_acc: 0.8390\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 8s 190us/step - loss: 0.5384 - acc: 0.8335 - val_loss: 0.5113 - val_acc: 0.8490\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 7s 173us/step - loss: 0.5192 - acc: 0.8407 - val_loss: 0.5039 - val_acc: 0.8522oss: 0.5150 - a\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 7s 175us/step - loss: 0.5078 - acc: 0.8436 - val_loss: 0.4822 - val_acc: 0.8597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18150c9bef0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, trainY, batch_size=100, nb_epoch=20, \n",
    "validation_data=(X_val, valY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/20\n",
      " 1800/42000 [>.............................] - ETA: 3s - loss: 0.3528 - acc: 0.8817"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 6s 135us/step - loss: 0.3491 - acc: 0.8900 - val_loss: 0.6430 - val_acc: 0.8291\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 6s 141us/step - loss: 0.3399 - acc: 0.8931 - val_loss: 0.6441 - val_acc: 0.8301\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 6s 137us/step - loss: 0.3339 - acc: 0.8953 - val_loss: 0.5974 - val_acc: 0.8413\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 6s 144us/step - loss: 0.3335 - acc: 0.8954 - val_loss: 0.6006 - val_acc: 0.8427\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 5s 125us/step - loss: 0.3244 - acc: 0.8980 - val_loss: 0.6333 - val_acc: 0.8333\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 6s 133us/step - loss: 0.3257 - acc: 0.8991 - val_loss: 0.6391 - val_acc: 0.8349\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 6s 143us/step - loss: 0.3203 - acc: 0.8987 - val_loss: 0.5994 - val_acc: 0.8442\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 5s 118us/step - loss: 0.3121 - acc: 0.9013 - val_loss: 0.6016 - val_acc: 0.8421\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 6s 131us/step - loss: 0.3101 - acc: 0.9030 - val_loss: 0.6447 - val_acc: 0.8322\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 6s 140us/step - loss: 0.3046 - acc: 0.9049 - val_loss: 0.6129 - val_acc: 0.8428\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 5s 122us/step - loss: 0.2974 - acc: 0.9057 - val_loss: 0.6495 - val_acc: 0.8312\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 5s 117us/step - loss: 0.2975 - acc: 0.9065 - val_loss: 0.6031 - val_acc: 0.8444\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 5s 117us/step - loss: 0.2914 - acc: 0.9074 - val_loss: 0.6070 - val_acc: 0.8431\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 5s 130us/step - loss: 0.2884 - acc: 0.9092 - val_loss: 0.6016 - val_acc: 0.8469- loss: 0.2886 - acc: \n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 5s 128us/step - loss: 0.2865 - acc: 0.9097 - val_loss: 0.6463 - val_acc: 0.8341\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 6s 133us/step - loss: 0.2928 - acc: 0.9075 - val_loss: 0.6292 - val_acc: 0.8393\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 5s 127us/step - loss: 0.2879 - acc: 0.9083 - val_loss: 0.6448 - val_acc: 0.8381\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 5s 119us/step - loss: 0.2772 - acc: 0.9114 - val_loss: 0.6543 - val_acc: 0.8357\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 6s 153us/step - loss: 0.2783 - acc: 0.9133 - val_loss: 0.6334 - val_acc: 0.8402\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 5s 122us/step - loss: 0.2679 - acc: 0.9138 - val_loss: 0.6194 - val_acc: 0.8467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18150d3c550>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, trainY, batch_size=100, nb_epoch=20, \n",
    "validation_data=(X_test, testY))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Understand the differences and trade-offs between traditional and NN classifiers with the help of\n",
    "classification metrics (5 points)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here we observe that Traditional classifiers(KNN) is giving very low accuracy. Also, it required long processing time."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Neural Network classifiers gave much better accuracy(84%) compared to traditional classifier. If we iterate through few more epochs, accuracy will increse further. Processing time was also low. It got completed in few minutes while KNN took 7-8 hours."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
